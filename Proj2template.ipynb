{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Least-Squares Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and load the MNIST datasets\n",
    "\n",
    "Download the training and test datasets. Use the provided function to load the first 5000 images and labels of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     42\u001b[0m     r \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m60000\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     images_2_show\u001b[38;5;241m.\u001b[39mappend(\u001b[43mx_train\u001b[49m[r])\n\u001b[1;32m     44\u001b[0m     titles_2_show\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining image [\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(r) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y_train[r]))    \n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = './'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte')\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "# Load MINST dataset\n",
    "\n",
    "# Implement your code to load: training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath\n",
    "# mnist_dataloader = \n",
    "# (x_train, y_train), (x_test, y_test) = \n",
    "\n",
    "\n",
    "# Show some random training and test images \n",
    "\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the data\n",
    "\n",
    "Identify the row and column indices of the pixels that have nonzero intensities in at least 600 of the training images. These will be the features used for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming x_train is a list of 28x28 images (each image is a list or array of shape (28, 28))\n",
    "num_imgs = len(x_train)\n",
    "pixel_dimensions = (28, 28)  # Assuming MNIST size (28x28 images)\n",
    "\n",
    "# Implement your code here\n",
    "\n",
    "num_features = len(pixels_to_consider)\n",
    "\n",
    "# Outputs\n",
    "print(f\"Number of features (selected pixels): {num_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the least-squares classifier\n",
    "\n",
    "Construct the matrix $A$ and vector $y$ as \n",
    "$$minimize \\ \\|A\\theta - y\\|_2 $$\n",
    "Solve the least-square problem to obtain the parameter vector $\\theta$. Create a plot showing the values of the entries of $\\theta$ at different pixel locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_feature_matrix_and_labels(x_data, y_data, pixels_to_consider, num_imgs=None):\n",
    "    # implement your code here\n",
    "    return A, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implement the least-squares classifier\n",
    "\n",
    "Load the first 5000 images of the test dataset. Using these images, compute the error rate, false positive rate, and false negative rate of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import lsqr\n",
    "\n",
    "# Implement your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code here to plot a heat map of the learned theta values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_theta_performance(x_test, y_test, pixels_to_consider, theta):\n",
    "    # implement your code here to compute the error rate, false positive rate, and false negative rate\n",
    "\n",
    "    return error_rate, false_positive_rate, false_negative_rate\n",
    "\n",
    "error_rate, false_positive_rate, false_negative_rate = test_theta_performance(x_test, y_test, pixels_to_consider, theta)\n",
    "print(f\"Performance of theta:\")\n",
    "print(f\"Error rate: {error_rate}\")\n",
    "print(f\"False positive rate: {false_positive_rate}\")\n",
    "print(f\"False negative rate: {false_negative_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Redo training with partial feature list\n",
    "\n",
    "Repeat steps 1-4, except use only the first 100 images and labels of the training dataset to train the classifier. Use the same features that you identified in Step 2. How did the error rate and false positive/negative rates change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code here\n",
    "\n",
    "error_rate, false_positive_rate, false_negative_rate = test_theta_performance(x_test, y_test, pixels_to_consider, theta_less_data)\n",
    "print(f\"Performance of theta_less_data:\")\n",
    "print(f\"Error rate: {error_rate}\")\n",
    "print(f\"False positive rate: {false_positive_rate}\")\n",
    "print(f\"False negative rate: {false_negative_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Feature Selection\n",
    "\n",
    "In what follows, we will experiment with changing the feature set. Let $M_{0}$ denote the number of features that you identified in Step 2, and let $M = 5000$. Choose a matrix $R \\in \\mathbb{R}^{M \\times M_{0}}$ whose entries are in $\\{1, -1\\}$ with equal probability. \n",
    "Letting $x_{i} \\in \\mathbb{R}^{M_{0}}$ denote the vector of features from Step 2 for the $i$-th image, the new feature vector is given by $\\max{\\{Rx_{i},0\\}}$. Train a least-squares classifier using this new set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import lsqr\n",
    "\n",
    "def LS_classifier_artificial_features(M, R, x_train, y_train, pixels_to_consider, num_imgs):\n",
    "    # implement your code here\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code to\n",
    "# Set parameters\n",
    "# Call the function to solve for theta\n",
    "theta_arti_features = LS_classifier_artificial_features(M, R, x_train, y_train, pixels_to_consider, num_imgs)\n",
    "\n",
    "# Output theta to verify\n",
    "print(f\"Solution theta shape: {theta.shape}\")\n",
    "print(f\"First few theta values: {theta[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the new classifier\n",
    "\n",
    "Compute the error rate, false positive rate, and false negative rate for the new classifier that you constructed in the previous step. Repeat the process with $M=20, 50, 1000, 5000, 10000$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# implement your code here to test the performance\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linAlgP2Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
